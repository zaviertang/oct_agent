/**
 * æ­£ç¡®çš„ OpenAI SDK ä»£ç†é…ç½®
 */
import OpenAI from 'openai';
import dotenv from 'dotenv';
import { HttpsProxyAgent } from 'https-proxy-agent';
import fetch from 'node-fetch';

dotenv.config();

const proxyUrl = process.env.HTTPS_PROXY || process.env.HTTP_PROXY || 'http://127.0.0.1:7890';

console.log('ğŸ§ª æµ‹è¯•æ­£ç¡®çš„ä»£ç†é…ç½®...\n');
console.log(`ğŸ“¡ ä»£ç†åœ°å€: ${proxyUrl}`);
console.log(`ğŸ”‘ API Key: ${process.env.OPENAI_API_KEY ? 'å·²é…ç½®' : 'âŒ æœªé…ç½®'}\n`);

try {
  // åˆ›å»ºä»£ç†agent
  const agent = new HttpsProxyAgent(proxyUrl);
  
  // åˆ›å»ºè‡ªå®šä¹‰ fetch å‡½æ•°
  const proxyFetch = (url, options = {}) => {
    return fetch(url, {
      ...options,
      agent
    });
  };
  
  // åˆ›å»º OpenAI å®¢æˆ·ç«¯
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    fetch: proxyFetch  // ä½¿ç”¨è‡ªå®šä¹‰ fetch
  });
  
  console.log('æ­£åœ¨è°ƒç”¨ OpenAI API...');
  
  const completion = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: 'ç”¨ä¸­æ–‡è¯´"ä½ å¥½"' }],
    max_tokens: 20
  });
  
  console.log('\nâœ… æˆåŠŸï¼');
  console.log('ğŸ“ AI å›å¤:', completion.choices[0].message.content);
  console.log('\nğŸ‰ ä»£ç†é…ç½®æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨äº†ï¼');
  
} catch (error) {
  console.error('\nâŒ å¤±è´¥:', error.message);
  if (error.cause) {
    console.error('åŸå› :', error.cause.message);
  }
}


