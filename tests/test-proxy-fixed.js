/**
 * ä½¿ç”¨ undici ProxyAgent çš„ä»£ç†æµ‹è¯•
 */
import { generateText } from 'ai';
import { openai } from '@ai-sdk/openai';
import dotenv from 'dotenv';
import { ProxyAgent } from 'node:undici';

dotenv.config();

const proxyUrl = process.env.HTTPS_PROXY || process.env.HTTP_PROXY || 'http://127.0.0.1:7890';

console.log('ğŸ§ª ä»£ç†æµ‹è¯• (ä½¿ç”¨ undici ProxyAgent)...\n');
console.log(`ğŸ“¡ ä»£ç†åœ°å€: ${proxyUrl}`);
console.log(`ğŸ”‘ API Key: ${process.env.OPENAI_API_KEY ? 'å·²é…ç½®' : 'âŒ æœªé…ç½®'}\n`);

try {
  // åˆ›å»ºä»£ç† agent
  const proxyAgent = new ProxyAgent(proxyUrl);
  
  // åˆ›å»ºè‡ªå®šä¹‰ fetch
  const customFetch = (url, options = {}) => {
    return fetch(url, {
      ...options,
      dispatcher: proxyAgent
    });
  };
  
  console.log('æ­£åœ¨è°ƒç”¨ OpenAI API...');
  
  const result = await generateText({
    model: openai('gpt-3.5-turbo', { fetch: customFetch }),
    prompt: 'ç”¨ä¸­æ–‡è¯´"ä½ å¥½"',
    maxTokens: 20
  });
  
  console.log('\nâœ… æˆåŠŸï¼');
  console.log('ğŸ“ AI å›å¤:', result.text);
  console.log('\nğŸ‰ ä»£ç†é…ç½®æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨äº†ï¼');
  console.log('\nâ–¶ï¸  è¿è¡Œä¸»ç¨‹åº: node main-proxy-fixed.js');
  
} catch (error) {
  console.error('\nâŒ å¤±è´¥:', error.message);
  console.error('\nğŸ’¡ è¯·æ£€æŸ¥:');
  console.error('  1. Clash/V2Ray æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Ÿ');
  console.error('  2. ä»£ç†ç«¯å£æ˜¯å¦æ˜¯ 7890ï¼Ÿ');
  console.error('  3. å°è¯•æ‰‹åŠ¨æŒ‡å®šç«¯å£:');
  console.error('     HTTPS_PROXY=http://127.0.0.1:ç«¯å£å· node test-proxy-fixed.js');
}

