/**
 * æœ€ç®€å•çš„æ–¹æ³•ï¼šç›´æ¥ä½¿ç”¨ OpenAI åŸç”Ÿ SDK + https-proxy-agent
 * æ— éœ€ Vercel AI SDK
 */
import OpenAI from 'openai';
import dotenv from 'dotenv';
import { HttpsProxyAgent } from 'https-proxy-agent';

dotenv.config();

const proxyUrl = process.env.HTTPS_PROXY || process.env.HTTP_PROXY || 'http://127.0.0.1:7890';

console.log('ğŸ§ª ä½¿ç”¨ OpenAI åŸç”Ÿ SDK æµ‹è¯•ä»£ç†...\n');
console.log(`ğŸ“¡ ä»£ç†åœ°å€: ${proxyUrl}`);
console.log(`ğŸ”‘ API Key: ${process.env.OPENAI_API_KEY ? 'å·²é…ç½®' : 'âŒ æœªé…ç½®'}\n`);

try {
  // åˆ›å»ºä»£ç†agent
  const agent = new HttpsProxyAgent(proxyUrl);
  
  // åˆ›å»º OpenAI å®¢æˆ·ç«¯
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    httpAgent: agent
  });
  
  console.log('æ­£åœ¨è°ƒç”¨ OpenAI API...');
  
  const completion = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: 'ç”¨ä¸­æ–‡è¯´"ä½ å¥½"' }],
    max_tokens: 20
  });
  
  console.log('\nâœ… æˆåŠŸï¼');
  console.log('ğŸ“ AI å›å¤:', completion.choices[0].message.content);
  console.log('\nğŸ‰ ä»£ç†é…ç½®æ­£ç¡®ï¼');
  console.log('\nğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥:');
  console.log('  1. åœ¨ .env æ–‡ä»¶æ·»åŠ : HTTPS_PROXY=http://127.0.0.1:7890');
  console.log('  2. è¿è¡Œä¸»ç¨‹åºï¼ˆä½¿ç”¨ OpenAI åŸç”Ÿç‰ˆæœ¬ï¼‰');
  
} catch (error) {
  console.error('\nâŒ å¤±è´¥:', error.message);
  console.error('\nğŸ’¡ è¯·æ£€æŸ¥:');
  console.error('  1. Clash/V2Ray æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Ÿ');
  console.error('  2. ä»£ç†ç«¯å£æ˜¯å¦æ˜¯ 7890ï¼Ÿ');
  console.error('  3. å°è¯•: HTTPS_PROXY=http://127.0.0.1:ç«¯å£å· node simple-proxy-test.js');
}


